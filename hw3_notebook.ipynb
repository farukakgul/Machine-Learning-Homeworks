{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5yghM_BMmkQ"
   },
   "source": [
    "<h1><center>CS 464</center></h1>\n",
    "<h1><center>Introduction to Machine Learning</center></h1>\n",
    "<h1><center>Spring 2020</center></h1>\n",
    "<h1><center>Homework 3</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ds6L6MMXMmkR"
   },
   "source": [
    "<h3><center>Due: May 19, 2020 23:55 (GMT+3)</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cCsDGpxqMmkT"
   },
   "source": [
    "### Instructions\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "    This homework contains both written and programming questions about neural networks. You should implement programming questions on this notebook. Each programming question has its own cell for your answer. You can implement your code directly in these cells, or you can call required functions which are defined in a different location for the given question. <b>Any other programming enviroment will NOT be accepted.</b>\n",
    "    </li>\n",
    "    <li>\n",
    "    For questions that you need to plot, your plot results have to be included in both cell output. For written questions, you may provide them either as comments in code cells or as seperate text cells. \n",
    "    </li>\n",
    "    <li>\n",
    "    You are <b>ONLY ALLOWED</b> to use libraries given below:\n",
    "        <ul>\n",
    "        <i>>google.colab.drive</i><br>\n",
    "         <i>>pandas</i><br>\n",
    "         <i>>numpy</i><br>\n",
    "         <i>>libraries included in Python standard library (time, os, sys etc.)</i><br>\n",
    "         <i>>libraries included in PyTorch framework (torch, torchvision etc.)</i><br>\n",
    "         <i>>PIL.Image</i><br>\n",
    "         <i>>matplotlib</i>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "    It is <b>NOT ALLOWED</b> to use a different deep learning framework than PyTorch.\n",
    "    </li>\n",
    "    <li>\n",
    "    You will submit only a single compressed file for this homework. Compress your notebook(\".ipynb\") and model (\".pth\") files as a gzipped TAR file or a ZIP file with the name CS464_HW3_Section#_Firstname_Lastname. Do not use any Turkish letters for any of your files including code files and model files. Upload your homework to the related section on Moodle.\n",
    "    </li>\n",
    "    <li>\n",
    "    This is an individual assignment for each student. That is, you are NOT allowed to share your workwith your classmates.</li>\n",
    "    <li> \n",
    "    If you do not follow the submission routes, deadlines and specifications, it will lead to a significant grade deduction.\n",
    "    </li>\n",
    "    <li> \n",
    "    For any question regarding this assignment, contact <b>ilayda.beyreli@bilkent.edu.tr</b>.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cE7TyUOpMmkU"
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UDBMnGMFlc50"
   },
   "source": [
    "You may use both anaconda or pip to install PyTorch to your own computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wbzHKKbMmkV"
   },
   "source": [
    "### Anaconda Installation\n",
    "\n",
    "<ul>\n",
    "    <li>Download anaconda from https://www.anaconda.com/download</li>\n",
    "    <li>Follow the instructions provided in https://conda.io/docs/user-guide/install/index.html#regular-installation</li>\n",
    "</ul>\n",
    "\n",
    "#### Creation of Virtual Environment\n",
    "\n",
    "<ul>\n",
    "    <li>Create python3.7 virtual environment for your hw3 using follow command from the command line<br>\n",
    "        <i>> conda create -n HW3 python=3.7 anaconda</i></li>\n",
    "    <li>Activate your virtual environment<br>\n",
    "        <i>> source activate HW3</i></li>\n",
    "    <li>When you create your virtual environment with \"anaconda\" metapackage, jupyter notebook should be installed. Try:<br>\n",
    "         <i>> jupyter notebook</i>\n",
    "</ul>\n",
    "\n",
    "\n",
    "#### Pytorch Installation with Anaconda\n",
    "\n",
    "You should install PyTorch to your virtual environment which is created for the hw3. Therefore, you should activate your homework virtual environment before to start PyTorch installation.\n",
    "<li>> source activate HW3</li>\n",
    "\n",
    "After you have activated the virtual environment, then use one of the following commands to install pytorch for CPU for your system. See https://pytorch.org/ for help.\n",
    "<ul>\n",
    "<li>For MacOS:<br>\n",
    "    <i>> conda install pytorch torchvision -c pytorch</i>\n",
    "</li>\n",
    "<li>For Linux:<br>\n",
    "    <i>> conda install pytorch-cpu torchvision-cpu -c pytorch</i>\n",
    "</li>\n",
    "<li>For Windows:<br>\n",
    "    <i>> conda install pytorch-cpu torchvision-cpu -c pytorch</i><br>\n",
    "</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oV6Va_SmV5i"
   },
   "source": [
    "###Pip3 Installation\n",
    "<ul>\n",
    "    <li>Download pip3 from https://pip.pypa.io/en/stable/installing/</li>\n",
    "    <li>If you are using Windows, you may need to add Python to your enviroment variables. You may use the following tutorial to install Python and pip.\n",
    "    https://phoenixnap.com/kb/how-to-install-python-3-windows</li>\n",
    "</ul>\n",
    "\n",
    "#### PyTorch Installation with Pip\n",
    "<ul>\n",
    "<li>For MacOS:<br>\n",
    "    <i>> pip3 install torch torchvision</i>\n",
    "</li>\n",
    "<li>For Linux:<br>\n",
    "    <i>> pip3 install torch==1.3.1+cpu torchvision==0.4.2+cpu -f https://download.pytorch.org/whl/torch_stable.html</i>\n",
    "</li>\n",
    "<li>For Windows:<br>\n",
    "    <i>> pip3 install torch==1.3.1+cpu torchvision==0.4.2+cpu -f https://download.pytorch.org/whl/torch_stable.html</i><br>\n",
    "</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGRjkX0pMmkY"
   },
   "source": [
    "## Question 1 Decison Trees [30 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0BcwAjaoMmkZ"
   },
   "source": [
    "![Dataset](https://drive.google.com/uc?export=view&id=1k6-cF0zIJ2TFtey1WZ8Y5wevWcDtKckd)\n",
    "\n",
    "  Consider the dataset shown above. You will train a binary decision tree using information gain as the splitting criteria. Consider the following stopping criteria (ie. early pruning criteria): If the entropy of a node is below a predefined threshold, $T$, stop splitting that node, and set it as a leaf.<br>\n",
    "\n",
    " Reminder: You are not allowed to put scanned images. Hence, you need to use drawing tools such as draw.io, Paint, Microsoft Powerpoint etc.<br>\n",
    "\n",
    "**a) [10 pts]** Draw the decision tree that is trained on this dataset without any pruning (i.e. $T=0$). Use <b>ID3 algorithm</b> and <b>entropy</b> as your impurity measure to construct your tree. Show your calculation for each split decision and justify your answer clearly.<br>\n",
    "\n",
    "**b) [5 pts]** Draw the decision boundaries resulting from the decision tree you have drawn for part a.<br>\n",
    "\n",
    "**c) [5 pts]** Assume we have a very large balanced dataset with 2 classes. Draw a hypothetical plot, which shows training and test errors (Y-axis) as $T$ changes from 1 to 0 (X-axis). Explain your rationale explicitly.<br>\n",
    "\n",
    "**d) [5 pts]** Is ID3 algorithm optimal? If yes, provide an intuition of optimality. If not, explain the reason explicitly.<br>\n",
    "\n",
    "**e) [5 pts]** If you used Gini Index as your impurity measure instead of entropy, would you obtain the same tree as in part a? Explain your reasoning clearly.<br>\n",
    "\n",
    "\n",
    "## Answers 1\n",
    "\n",
    "**a)** \n",
    "<br>\n",
    "[Tree](https://drive.google.com/open?id=1XVTz56ZWXwEF98y9V3NoEpWxwWwS39wz)<br>\n",
    "  //Click on \"Tree\" which directs you to google drive png file.<br><br>\n",
    "  // \"Tree\", \"Boundary\", \"Plot\" and \"Gini\" are image links that direct you to drive. I added these images to zip file to prevent errors.\n",
    "  \n",
    "H(Class) = 1/2 x log2 + 1/2 x log2  = 1\n",
    "\n",
    "Drawing a decision boundary based on x2 value always results in two classes, which have equal number of blue<br>\n",
    "and red class samples. In other words, if a decision boundary is drawn parallel to the x1 axis information <br>\n",
    "gain will be equal to 0. Thus, all the decision boundaries are drawn parallel to x1 axis.<br>\n",
    "\n",
    "Possible Boundary 1.1 ( X1 < 3/2 )<br>\n",
    "<br>\n",
    "H(Class | X1 < 3/2) = 1 x log1 = 0<br>\n",
    "H(Class | X1 >= 3/2) = 3/4 x log4/3 +  1/4 x log4 = 0.81<br>\n",
    "Weighted Average =  1/3 x 0 + 2/3 x 0.81= 0.54 <br>\n",
    "Information Gain = 1 - 0.54 = 0.46<br>\n",
    "\n",
    "Possible Boundary 1.2 ( X1 < 4 )<br>\n",
    "<br>\n",
    "H(Class | X1 < 4) = 1 x log1 = 0<br>\n",
    "H(Class | X1 >= 4) = 2/3 x log3/2 +  1/3 x log3 = 0.92<br>\n",
    "Weighted Average =  1/2 x 0.92 + 1/2 x 0.92 = 0.92 <br>\n",
    "Information Gain = 1 - 0.92 = 0.08<br>\n",
    "\n",
    "Possible Boundary 1.3 ( X1 < 13/2 )<br>\n",
    "<br>\n",
    "H(Class | X1 < 13/2) = 3/4 x log4/3 + 1/4 x log4  = 0.81<br>\n",
    "H(Class | X1  13/2) =1 x log1 = 0<br>\n",
    "Weighted Average =  2/3 x 0.81 = 0.54 <br>\n",
    "Information Gain = 1 - 0.54 = 0.46<br><br>\n",
    "\n",
    "\n",
    "The highest Information Gain is yielded when one of the possible boundary 1.1 and 1.3 is selected.<br>\n",
    "Thus, I am going to use Possible Boundary 1.1 as the first decision boundary.\n",
    "<br>\n",
    "\"******************************************\"\n",
    "<br>\n",
    "H(Class) = 3/4 x log4/3 + 1/4 x log4  = 0.82\n",
    "<br>\n",
    "Possible Boundary 2.1 ( X1 < 4 )<br>\n",
    "<br>\n",
    "H(Class | X1 < 4) = 1 x log1 = 0<br>\n",
    "H(Class | X1 >= 4) = 2/3 x log3/2 +  1/3 x log3 = 0.92<br>\n",
    "Weighted Average =  1/4 x 0 + 3/4 x 0.92 = 0.69 <br>\n",
    "Information Gain = 0.82 - 0.69 = 0.13<br>\n",
    "\n",
    "Possible Boundary 2.2 ( X1 < 13/2 )<br>\n",
    "<br>\n",
    "H(Class | X1 < 13/2) = 1/2 x log1/2 + 1/2 x log1/2  = 1<br>\n",
    "H(Class | X1  13/2) =1 x log1 = 0<br>\n",
    "Weighted Average =  1/2 x 1 = 0.5 <br>\n",
    "Information Gain = 0.82 - 0.5 = 0.32<br><br>\n",
    "\n",
    "The highest Information Gain is yielded when the possible boundary 2.2 is selected.<br>\n",
    "Thus, I am going to use Possible Boundary 2.2 as the seconds decision boundary.<br>\n",
    "\"******************************************\"\n",
    "<br>\n",
    "H(Class) = 1/2 x log2 + 1/2 x log2  = 1\n",
    "<br>\n",
    "Possible Boundary 3.1 ( X1 < 4 )<br>\n",
    "H(Class | X1 < 4) = 1 x log1 = 0<br>\n",
    "H(Class | X1 >= 4) = 1 x log1 = 0<br>\n",
    "Weighted Average =  1/2 x 0 + 1/2 x 0 = 0 <br>\n",
    "Information Gain = 1 - 0 = 1<br>\n",
    "\n",
    "All the samples are correctly classified after 3 decision boundary is chosen.\n",
    "\n",
    "**b)** \n",
    "<br>\n",
    "[Boundary](https://drive.google.com/open?id=1-vKOXORM43MKtCTVxNItUbPO-aaRDVAb)\n",
    "<br><br>\n",
    "**c)**\n",
    "<br>\n",
    "[Plot](https://drive.google.com/open?id=1qtNVzq8WJZJAHcgSEfhIXnuaW-fwuqNY)\n",
    "<br>\n",
    "Decreasing the value of T always results in decrease in error of training set. However, after a point test error <br> starts to increase because the model overfits to the training set. Thus, since the generalization of the <br> model is not good, unseen data is predicted incorrectly.\n",
    "<br><br>\n",
    "**d)**\n",
    "\n",
    "For this question, ID3 algorithm worked well because it provided a short path(1+2+3+3 = 9, in total). Also, since it uses a greedy approach, it is really fast.\n",
    "\n",
    "However, ID3 is not optimal algorithm. The first reason is that only one attribute is tested at an instant thus consuming a lot of time. For example, after drawing the first decision boundary, the second decision boundary that test x1 and x2 simultaneously could complete the tree(circling the remaining 2 blue samples). \n",
    "\n",
    "As a final remark, classifying the continuous data may prove to be expensive in terms of computation, as many trees have to be generated to see where to break the continuum.  One disadvantage of ID3 is that when given a large number of input values, it is overly sensitive to features with a large number of values.<br>\n",
    "**e)**\n",
    "<br>\n",
    "Yes, it I would use Gini Index as my impurity measure instead of entropy, I would obtain the same tree as in part a. \n",
    "[Gini](https://drive.google.com/open?id=1CQXr1cYPh-XnLFO3oFTnf17eIpm9AOVD)\n",
    "<br> \n",
    "As seen from the graph, entropy and Gini's approach to the problem give parallel results. Also, I did the calculation of same decision tree by using Gini as impurity measure:\n",
    "\n",
    "Possible Boundary 1.1 ( X1 < 3/2 )<br>\n",
    "<br>\n",
    "Gini1 ( X1 < 3/2) = 1 - 1^2 = 0<br>\n",
    "Gini2 ( X1 >= 3/2) = 1 - (1/4)^2 - (3/4)^2 = 3/8<br>\n",
    "Weighted Average =  3/8 x 3/4 + 0 = 9 / 32 <br>\n",
    "\n",
    "Possible Boundary 1.2 ( X1 < 4 )<br>\n",
    "<br>\n",
    "Gini1 ( X1 < 4) = 1 - (2/3)^2 - (1/3)^2 = 4/9<br>\n",
    "Gini2 ( X1 >= 4) = 1 - (2/3)^2 - (1/3)^2 = 4/9<br>\n",
    "Weighted Average =  4/9 <br>\n",
    "\n",
    "Possible Boundary 1.3 ( X1 < 13/2 )<br>\n",
    "<br>\n",
    "Gini1 ( X1 < 3/2) = 1 - 1^2 = 0<br>\n",
    "Gini2 ( X1 >= 3/2) = 1 - (1/4)^2 - (3/4)^2 = 3/8<br>\n",
    "Weighted Average =  3/8 x 3/4 + 0 = 9 / 32 <br><br>\n",
    "\n",
    "The highest purity is yielded when one of the possible boundary 1.1 and 1.3 is selected.<br>\n",
    "Thus, I am going to use Possible Boundary 1.1 as the first decision boundary.\n",
    "<br>\n",
    "\"******************************************\"\n",
    "<br>\n",
    "<br>\n",
    "Possible Boundary 2.1 ( X1 < 4 )<br>\n",
    "<br>\n",
    "Gini1 ( X1 < 4) = 1 - 1^2 = 0<br>\n",
    "Gini2 ( X1 >= 4) = 1 - (2/3)^2 - (1/3)^2 = 4/9<br>\n",
    "Weighted Average =  4/9 x 2/3 = 8 /27 <br>\n",
    "Information Gain = 1 - 0.92 = 0.08<br>\n",
    "\n",
    "Possible Boundary 2.2 ( X1 < 13/2 )<br>\n",
    "<br>\n",
    "Gini1 ( X1 < 3/2) = 1 - (1/2)^2 - 1/2)^2 = 1/2<br>\n",
    "Gini2 ( X1 >= 3/2) = 1 - 1^2 = 0<br>\n",
    "Weighted Average =  1/2 x 1/2 + 0 = 1/4 <br><br>\n",
    "\n",
    "\n",
    "The highest impurity is yielded when the possible boundary 2.2 is selected.<br>\n",
    "Thus, I am going to use Possible Boundary 2.2 as the seconds decision boundary.<br>\n",
    "\"******************************************\"\n",
    "<br>\n",
    "<br>\n",
    "Possible Boundary 3.1 ( X1 < 4 )<br>\n",
    "Gini1 ( X1 < 4) = 1 - 1^2 = 0<br>\n",
    "Gini2 ( X1 >= 4) = 1 - 1^2 = 0<br>\n",
    "Weighted Average =  1/2 x 0 + 1/2 x 0 = 0 <br>\n",
    "\n",
    "As seen, decision boundaries are exactly the same when Gini is used as impurity measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SmN0va8GMmka"
   },
   "source": [
    "## Question 2 [70 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3mspgJlMmkb"
   },
   "source": [
    "In this question you are asked to perform binary classification on Ocular Disease Recognition, ODIR5k, dataset. First, you will implement a three-layer neural network, and then a 3 layer convolutional neural network (CNN) to classify retinal images of 3500 patiens as either \"normal\" or \"abnormal/disease\".<br><br>\n",
    "The dataset has been preprocessed in such a way that the right and the left retinal images from the same patient are combined, downsized and stored as H:128 X W:256 RGB images. The label for each patient is also given to you in another .xlsx file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qgzLrMkW8xxU"
   },
   "source": [
    "### 2.1. Multi Layer Perceptron (MLP) [30 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4yzlbHxVMmkc"
   },
   "source": [
    "#### Data Loader [7pts]\n",
    "\n",
    "An important part of such a task is to implement your own data loader. In this homework, a partial loader is provided to you. This loader is going to be based on a base class named \"Dataset\", provided in PyTorch library. You need to complete the code below to create your custom \"OcularDataset\" class which will be able to load your dataset. <br><br>\n",
    "Implement the functions whose proptotypes are given. Follow the TODO notes below. You have to divide the files into three sets as <b>train (5/7)</b>, <b>validation (1/7)</b> and **test (1/7)** sets.  These non-overlapping splits, which are subsets of OcularDataset, should be retrieved using the \"get_dataset\" function. Here, you are also supposed to flatten the image into a vector (also to grayscale) to be compatible with MLP. Note that the pixel values also needs to be normalized to [0,1] range.\n",
    "<br><br>\n",
    "\n",
    "Hint: The dataset is not normalized and your results will heavily depend on your input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import xlrd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "from torch._utils import _accumulate\n",
    "import random\n",
    "from torch import randperm\n",
    "from torch.utils.data import *\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class OcularDataset(Dataset):\n",
    "\n",
    "    #  TODO:\n",
    "    #  Define constructor for AnimalDataset class\n",
    "    #  HINT: You can pass processed data samples and their ground truth values as parameters\n",
    "    def __init__(self, **kwargs):\n",
    "        self.data = kwargs['data']\n",
    "        self.labels = kwargs['labels']\n",
    "\n",
    "    '''This function should return sample count in the dataset'''\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    '''This function should return a single sample and its ground truth value from the dataset corresponding to index parameter '''\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        return sample, label\n",
    "\n",
    "# def get_dataset(root):\n",
    "# TODO:\n",
    "#  Read dataset files\n",
    "# Construct training, validation and test sets\n",
    "# Normalize & flatten datasets\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    def __getname__(self, index):\n",
    "        return self.imgs[index][0]\n",
    "\n",
    "\n",
    "# return train_dataset, val_dataset, test_dataset#\n",
    "\n",
    "def get_dataset(root, labels_excel_file):\n",
    "    # Read dataset files from \"/home/omer/Desktop/2.2/cs464/cs464_spring20_hw3\" folder\n",
    "    \n",
    "    \n",
    "    # data_path = '/home/omer/Desktop/2.2/cs464/cs464_spring20_hw3/'\n",
    "    # the code above reads from my computer path\n",
    "    \n",
    "    data_path = root\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "        torchvision.transforms.ToTensor()])\n",
    "\n",
    "    dataset = ImageFolderWithPaths(\n",
    "        root=data_path,\n",
    "        transform=transform)\n",
    "\n",
    "    data_np = np.ndarray(shape=(3500, 128 * 256))\n",
    "    for el in range(3500):\n",
    "        data_np[el] = (dataset[el][0].numpy()).reshape((1, 128 * 256))\n",
    "\n",
    "    data_np = np.float32(data_np.reshape(3500, 128* 256))\n",
    "\n",
    "    # normalizing samples\n",
    "    min_column = np.amin(data_np, axis=0)\n",
    "    max_column = np.amax(data_np, axis=0)\n",
    "    data_np = (data_np - min_column) / (max_column - min_column)\n",
    "\n",
    "    data_np = torch.from_numpy(data_np)\n",
    "\n",
    "    # Split dataset samples into the 3 part for training, validation and test\n",
    "\n",
    "    indices = np.arange(0, 3500, 1)\n",
    "    np.random.shuffle(indices)\n",
    "    training_set = data_np[indices[0:2500]]\n",
    "    val_set = data_np[indices[2500:3000]]\n",
    "    test_set = data_np[indices[3000:3500]]\n",
    "\n",
    "\n",
    "    # excel_file = \"/home/omer/Desktop/2.2/cs464/cs464_spring20_hw3/labels.xlsx\"\n",
    "    excel_file = labels_excel_file\n",
    "    df   = pd.read_excel(excel_file, sheet_name=\"Sheet1\")\n",
    "\n",
    "    file_names = df[0]\n",
    "    labels = df[1]\n",
    "    file_names = np.array(file_names.tolist())\n",
    "    labels = np.array(labels.tolist())\n",
    "    file_names = list(map(str, file_names))\n",
    "    enum = np.c_[file_names, labels]\n",
    "    enum = enum[enum[:, 0].argsort()]\n",
    "    final = np.ndarray((3500,2))\n",
    "    for a in range(len(enum)):\n",
    "        for b in range (2):\n",
    "            final[a][b] = int(enum[a][b])\n",
    "\n",
    "    final = final.astype(int)\n",
    "\n",
    "    labels = final.transpose()[1]\n",
    "\n",
    "    labels1 = labels[indices[0:int(len(labels) * 5 / 7)]]\n",
    "    labels2 = labels[indices[int(len(labels) * 5 / 7):int(len(labels) * 6 / 7)]]\n",
    "    labels3 = labels[indices[int(len(labels) * 6 / 7):]]\n",
    "\n",
    "    labels1 = pd.Series(list(labels1))\n",
    "    labels2 = pd.Series(list(labels2))\n",
    "    labels3 = pd.Series(list(labels3))\n",
    "\n",
    "\n",
    "    kwargs = {'data': training_set, 'labels': labels1}\n",
    "    train_dataset = OcularDataset(**kwargs)\n",
    "\n",
    "    kwargs = {'data': val_set, 'labels': labels2}\n",
    "    val_dataset = OcularDataset(**kwargs)\n",
    "\n",
    "\n",
    "    kwargs = {'data': test_set, 'labels': labels3}\n",
    "    test_dataset = OcularDataset(**kwargs)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OMfyonGRMmke"
   },
   "source": [
    "#### Neural Network [4 pts]\n",
    "\n",
    "Now, implement your three hidden layer neural network. FNet class will represent your neural network. The layer descriptions are as follows:<ul>\n",
    "    <i>> Input layer will have ReLU activation. You should decide the number of input neurons.</i><br>\n",
    "    <i>> First hidden layer will have 1024 neuros with ReLU activation </i><br>\n",
    "    <i>> Second hidden layer will have 256 neuros with ReLU activation </i><br>\n",
    "    <i> You should decide the number of output neurons and pick a proper activation function for the output layer. </i><br>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adM6pBIp6cIa"
   },
   "outputs": [],
   "source": [
    "class FNet(nn.Module):\n",
    "    '''Define your neural network'''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "    #  you can add any additional parameters you want\n",
    "    # TODO:\n",
    "    #  You should create your neural network here\n",
    "        super(FNet, self).__init__()\n",
    "        self.input = nn.Sequential(nn.Linear(32768, 1024), nn.ReLU())\n",
    "        self.hidden1 = nn.Sequential(nn.Linear(1024, 256), nn.ReLU())\n",
    "        self.hidden2 = nn.Sequential(nn.Linear(256, 32), nn.ReLU())\n",
    "        self.output = nn.Sequential(nn.Linear(32, 1), nn.ReLU())\n",
    "\n",
    "    def forward(self, X):\n",
    "#  you can add any additional parameters you want\n",
    "#  TODO:\n",
    "#  Forward propagation implementation should be here\n",
    "        out = self.input(X)\n",
    "        out = self.hidden1(out)\n",
    "        out = self.hidden2(out)\n",
    "        out = self.output(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4-GhJe0Mmkf"
   },
   "source": [
    "#### Training [10 pts]\n",
    "\n",
    "Complete the code snippet below to train your network. You need to carefully select the appropriate loss function and tune hyper-parameters. Use SGD optimizer for this question.<br>\n",
    "So far, you should have created three dataset splits for train, validation and test. You will need to load these splits at this phase. Make sure that you shuffle the samples in the training split. Save training loss and training accuracy of each iteration (each batch) and also save validation loss and accuracy at each epoch to use them in the next part for plotting.<br>\n",
    "Your model is going to run upto at most 100 epochs. Pick the best model so far as your final model and save this model as a \".pth\" file. <br>\n",
    "Note that the best accuracy does not always imply the best model. Try to track losses instead of accuracies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlkS5jVR6kNb"
   },
   "outputs": [],
   "source": [
    "\n",
    "max_epoch = 100\n",
    "train_batch = 50\n",
    "val_batch = 20\n",
    "test_batch = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Inspired from: https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = get_dataset(\"./\", \"./\")\n",
    "\n",
    "def main(train_results, val_results):  # you are free to change parameters\n",
    "\n",
    "    # Create train dataset loader\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch, num_workers=0, shuffle=True)\n",
    "\n",
    "    # Create validation dataset loader\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=test_batch, num_workers=0)\n",
    "\n",
    "    # initialize your GENet neural network\n",
    "    model = FNet()\n",
    "    # define your loss function\n",
    "    pos_weight = torch.FloatTensor([2])\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.SGD(list(model.parameters()), lr=learning_rate, momentum=0.9,\n",
    "                                weight_decay=5e-04)  # you can play with momentum and weight_decay parameters as well\n",
    "\n",
    "\n",
    "    # start training\n",
    "    # for each epoch calculate validation performance\n",
    "    # save best model according to validation performance\n",
    "\n",
    "    best_acc = 0\n",
    "    best_loss = 100\n",
    "    best_path = \"FNet_best_model.pth\"\n",
    "    for epoch in range(max_epoch):\n",
    "        res = train(epoch, model, criterion, optimizer, train_loader)\n",
    "        train_results.append(res)\n",
    "        res = test(model, val_loader, criterion)\n",
    "        acc = res[0]\n",
    "        loss = res[1]\n",
    "        val_results.append(res)\n",
    "        if loss < best_loss:\n",
    "            best_acc = acc\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "\n",
    "''' Train your network for a one epoch '''\n",
    "\n",
    "\n",
    "def train(epoch, model, criterion, optimizer, loader):  # you are free to change parameters\n",
    "    model.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "\n",
    "\n",
    "    t1 = time.time()\n",
    "    for batch_idx, (data, labels) in enumerate(loader):\n",
    "        data_time.update(time.time() - t1)\n",
    "\n",
    "        # Implement training code for a one iteration\n",
    "        # x = torch.reshape(data[0], (train_batch, 32768))\n",
    "        x = data.float()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "        loss = criterion(output, labels)\n",
    "        predicted = (output>0.0).float()\n",
    "        acc = sum([1 if item[0] == item[1] else 0 for item in zip(predicted, labels)]) / len(labels)\n",
    "        accuracies.update(acc, train_batch)\n",
    "        losses.update(loss.item(), train_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - t1)\n",
    "        t1 = time.time()\n",
    "\n",
    "        print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "              'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "              'Data {data_time.val:.4f} ({data_time.avg:.4f})\\t'\n",
    "              'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "              'Accu {acc.val:.4f} ({acc.avg:.4f})\\t'.format(\n",
    "            epoch + 1, batch_idx + 1, len(loader),\n",
    "            batch_time=batch_time,\n",
    "            data_time=data_time,\n",
    "            loss=losses,\n",
    "            acc=accuracies))\n",
    "\n",
    "    return accuracies.avg, losses.avg\n",
    "\n",
    "\n",
    "''' Test&Validate your network '''\n",
    "\n",
    "\n",
    "def test(model, loader, criterion):  # you are free to change parameters\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t1 = time.time()\n",
    "        for batch_idx, (data, labels) in enumerate(loader):\n",
    "            # Implement test code\n",
    "            # x = torch.reshape(data[0], (test_batch, 32768))\n",
    "            x = data\n",
    "            output = model(x)\n",
    "            labels = labels.unsqueeze(1).float()\n",
    "            loss = criterion(output, labels)\n",
    "            predicted = (output>0.0).float()\n",
    "            acc = sum([1 if item[0] == item[1] else 0 for item in zip(predicted, labels)]) / len(labels)\n",
    "            accuracies.update(acc, test_batch)\n",
    "            losses.update(loss.item(), test_batch)\n",
    "            batch_time.update(time.time() - t1)\n",
    "            t1 = time.time()\n",
    "\n",
    "        print('Time {batch_time.avg:.3f}\\t'\n",
    "              'Accu {acc.avg:.4f}\\t'\n",
    "              'Loss {loss.avg:.4f}\\t'.format(\n",
    "            batch_time=batch_time,\n",
    "            acc=accuracies,\n",
    "            loss=losses))\n",
    "\n",
    "        return accuracies.avg, losses.avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SWJZLiIiMmkj"
   },
   "source": [
    "#### Plotting Your Results [4 pts]\n",
    "\n",
    "You need to provide two distinct plots, one demonstrating training and validation losses in y axis and iteration in the x axis and the other demonstrating training and validation accuracies in the y axis and iteration  in the x axis. <br><br>\n",
    "Please note that we need these plots to see if your model behaves as expected. Therefore, you may lose additional points if you do not provide these plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDfGUr10Mmkj"
   },
   "outputs": [],
   "source": [
    "train_res = list()\n",
    "val_res = list()\n",
    "main(train_res, val_res)\n",
    "\n",
    "train_acc, train_loss = zip(*train_res)\n",
    "val_acc, val_loss = zip(*val_res)\n",
    "\n",
    "plt.plot(range(1, max_epoch+1), train_acc, label=\"train_acc\")\n",
    "plt.plot(range(1, max_epoch+1), val_acc, label=\"val_acc\")\n",
    "plt.title(\"Epoch - Accuracy Graph\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, max_epoch+1), train_loss, label=\"train_loss\")\n",
    "plt.plot(range(1, max_epoch+1), val_loss, label=\"val_loss\")\n",
    "plt.title(\"Epoch - Loss Graph\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[accuracy.png](https://drive.google.com/open?id=14SSbqF2o-awR1xKp07M7n0N4Sb4-CIO2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[loss.png](https://drive.google.com/open?id=1DoGjzKC3gwUAoPYPwOnd876zpp14Jl33)\n",
    "<br>\n",
    "I added images to zip file, as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P7v8am0hMmkm"
   },
   "source": [
    "#### Testing [5 pts]\n",
    "\n",
    "Test your final, i.e. best, model on your test set. Calculate confusion matrix, F1 score, precision and recall values and report these findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aq6YqUadMmkn"
   },
   "outputs": [],
   "source": [
    "# write your code in this cell to test your best model with the test dataset\n",
    "# Create test dataset loader\n",
    "testloader = DataLoader(test_dataset, batch_size=test_batch)\n",
    "\n",
    "best_path = \"FNet_best_model.pth\"\n",
    "model = FNet()\n",
    "checkpoint = torch.load(best_path)\n",
    "if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "batch_time = AverageMeter()\n",
    "accuracies = AverageMeter()\n",
    "\n",
    "labels_list = list()\n",
    "predictions_list = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    t1 = time.time()\n",
    "    for batch_idx, (data, labels) in enumerate(testloader):\n",
    "        # Implement test code\n",
    "        # x = torch.reshape(data[0], (test_batch, 32768))\n",
    "        x = data\n",
    "        output = model(x)\n",
    "        predicted = (output>0.0).float()\n",
    "        labels_list.append(list(np.asarray(labels)))\n",
    "        predictions_list.append(list(np.asarray(predicted)))\n",
    "        acc = sum([1 if item[0] == item[1] else 0 for item in zip(predicted, labels)]) / len(data)\n",
    "        accuracies.update(acc, x.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - t1)\n",
    "        t1 = time.time()\n",
    "\n",
    "    print('Time {batch_time.avg:.3f}\\t'\n",
    "          'Accu {acc.avg:.4f}\\t'.format(\n",
    "        batch_time=batch_time,\n",
    "        acc=accuracies))\n",
    "\n",
    "predictions_list = [item for sublist in predictions_list for item in sublist]\n",
    "labels_list = [item for sublist in labels_list for item in sublist]\n",
    "a = np.array(predictions_list)\n",
    "b = np.array(labels_list)\n",
    "tp = 0\n",
    "for i in range(500):\n",
    "    if a[i] == 1 and b[i] == 1:\n",
    "        tp += 1\n",
    "tn = 0\n",
    "for i in range(500):\n",
    "    if a[i] == 0 and b[i] == 0:\n",
    "        tn += 1\n",
    "fp = 0\n",
    "for i in range(500):\n",
    "    if a[i] == 1 and b[i] == 0:\n",
    "        fp += 1\n",
    "fn = 0\n",
    "for i in range(500):\n",
    "    if a[i] == 0 and b[i] == 1:\n",
    "        fn += 1\n",
    "\n",
    "print(\"\\n   Labels\\n\")\n",
    "print(tp, \"      \", fp)\n",
    "print(\"               predictions\" )\n",
    "print(fn, \"    \", tn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Measure: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.5020<br>\t\n",
    "\n",
    "Confusion Matrix:<br>\n",
    "\n",
    "   Labels<br>\n",
    "\n",
    "(109  ,  197)<br>\n",
    "(52   ,  142)  predictions<br>\n",
    "\n",
    "Precision:   0.3562091503267974<br>\n",
    "Recall:      0.6770186335403726<br>\n",
    "F1 Measure:  0.4668094218415418<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://drive.google.com/open?id=1A2OxQ6kuaj3Ie-i_VIdcnKi-r4a9Qtym\n",
    "<br>\n",
    "that is a link to my fnet_best_model.pth\n",
    "<br>\n",
    "https://drive.google.com/open?id=1S7J-JYQCczoBe3JlgGiifOusvajzb9St\n",
    "<br>\n",
    "that is a link to my convnet_best_model.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-J6f1QPMmk3"
   },
   "source": [
    "### 2.2. Convolutional Neural Network (CNN) [30 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ssXrFEtjMmk4"
   },
   "source": [
    "#### Data Loader [5 pts]\n",
    "\n",
    "In this part, you will train a CNN for the same problem. Again, the pixel values need to be normalized to [0,1] range. Please do **not** change images to grayscale this time. First, implement the data loader (OcularDataset). You have to divide the files into three sets which are <b>train (5/7)</b>, <b>validation (1/7)</b> and **test (1/7)**.  These non-overlapping splits, which are subsets of OcularDataset, should be retrieved using the \"get_dataset\" function.<br> You may use your data loader from the previous sections with propoer modifications. Note that this time you do **not** need to flatten the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLpZ2tCnMmk4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import xlrd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "from torch._utils import _accumulate\n",
    "import random\n",
    "from torch import randperm\n",
    "from torch.utils.data import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class OcularDataset(Dataset):\n",
    "\n",
    "    #  TODO:\n",
    "    #  Define constructor for AnimalDataset class\n",
    "    #  HINT: You can pass processed data samples and their ground truth values as parameters\n",
    "    def __init__(self, **kwargs):\n",
    "        self.data = kwargs['data']\n",
    "        self.labels = kwargs['labels']\n",
    "\n",
    "    '''This function should return sample count in the dataset'''\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    '''This function should return a single sample and its ground truth value from the dataset corresponding to index parameter '''\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        return sample, label\n",
    "\n",
    "\n",
    "# def get_dataset(root):\n",
    "# TODO:\n",
    "#  Read dataset files\n",
    "# Construct training, validation and test sets\n",
    "# Normalize & flatten datasets\n",
    "\n",
    "# return train_dataset, val_dataset, test_dataset#\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    def __getname__(self, index):\n",
    "        return self.imgs[index][0]\n",
    "\n",
    "def get_dataset(root, label_excel_file):\n",
    "    #data_path = '/home/omer/Desktop/2.2/cs464/cs464_spring20_hw3/'\n",
    "    # the code above is my path\n",
    "    data_path = root\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()])\n",
    "\n",
    "    dataset = ImageFolderWithPaths(\n",
    "        root=data_path,\n",
    "        transform=transform)\n",
    "\n",
    "    data_np = np.ndarray(shape=(3500, 3 * 128 * 256))\n",
    "    for el in range(3500):\n",
    "        data_np[el] = (dataset[el][0].numpy()).reshape((1, 3 * 128 * 256))\n",
    "\n",
    "    data_np = np.float32(data_np.reshape(3500, 3 * 128 * 256))\n",
    "\n",
    "    #normalization\n",
    "    min_column = np.amin(data_np, axis=0)\n",
    "    max_column = np.amax(data_np, axis=0)\n",
    "    data_np = (data_np - min_column) / (max_column - min_column)\n",
    "\n",
    "    data_np = data_np.reshape((3500, 3, 128, 256))\n",
    "\n",
    "    data_np = torch.from_numpy(data_np)\n",
    "\n",
    "    # Split dataset samples into the 3 part for training, validation and test\n",
    "\n",
    "    indices = np.arange(0, 3500, 1)\n",
    "    np.random.shuffle(indices)\n",
    "    training_set = data_np[indices[0:2500]]\n",
    "    val_set = data_np[indices[2500:3000]]\n",
    "    test_set = data_np[indices[3000:3500]]\n",
    "\n",
    "    \n",
    "    # excel_file = \"/home/omer/Desktop/2.2/cs464/cs464_spring20_hw3/labels.xlsx\"\n",
    "    # root path of my labels file\n",
    "    \n",
    "    excel_file = label_excel_file\n",
    "    df = pd.read_excel(excel_file, sheet_name=\"Sheet1\")\n",
    "\n",
    "    file_names = df[0]\n",
    "    labels = df[1]\n",
    "    file_names = np.array(file_names.tolist())\n",
    "    labels = np.array(labels.tolist())\n",
    "    file_names = list(map(str, file_names))\n",
    "    enum = np.c_[file_names, labels]\n",
    "    enum = enum[enum[:, 0].argsort()]\n",
    "    final = np.ndarray((3500, 2))\n",
    "    for a in range(len(enum)):\n",
    "        for b in range(2):\n",
    "            final[a][b] = int(enum[a][b])\n",
    "\n",
    "    final = final.astype(int)\n",
    "\n",
    "    labels = final.transpose()[1]\n",
    "\n",
    "    labels1 = labels[indices[0:int(len(labels) * 5 / 7)]]\n",
    "    labels2 = labels[indices[int(len(labels) * 5 / 7):int(len(labels) * 6 / 7)]]\n",
    "    labels3 = labels[indices[int(len(labels) * 6 / 7):]]\n",
    "\n",
    "    labels1 = pd.Series(list(labels1))\n",
    "    labels2 = pd.Series(list(labels2))\n",
    "    labels3 = pd.Series(list(labels3))\n",
    "\n",
    "    kwargs = {'data': training_set, 'labels': labels1}\n",
    "    train_dataset = OcularDataset(**kwargs)\n",
    "\n",
    "    kwargs = {'data': val_set, 'labels': labels2}\n",
    "    val_dataset = OcularDataset(**kwargs)\n",
    "\n",
    "    kwargs = {'data': test_set, 'labels': labels3}\n",
    "    test_dataset = OcularDataset(**kwargs)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-RsQD3EMmk8"
   },
   "source": [
    "#### Convolutional Neural Network [8 pts]\n",
    "\n",
    "Now implement your CNN. ConvNet class will represent your convolutional neural network. Implement 3 layers of convolution: \n",
    "1. <i>> 8 filters with size of 3 x 3 x 3 with stride 1 and no padding,</i><br> \n",
    "    <i>> ReLU </i><br>\n",
    "2. <i>> 16 filters with size of 3 x 3 x 3 with stride 1 and no padding,</i><br>\n",
    "    <i>> ReLU </i><br>\n",
    "    <i>> MaxPool 2 x 2 </i><br>   \n",
    "3. <i>> 32 filters with size of 3 x 3 x 3 with stride 1 and no padding,</i><br>\n",
    "    <i>> ReLU </i><br>\n",
    "    <i>> MaxPool 2 x 2 </i><br>\n",
    "\n",
    "As a classification layer, you need to add only one more fully-connected layer at the end of the network. You need to choose the appropriate input and output neuron sizes and the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGiD0Y_oMmk9"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    '''Define your neural network'''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "    #  you can add any additional parameters you want\n",
    "    # TODO:\n",
    "    #  You should create your neural network here\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32*30*62,1)\n",
    "        )\n",
    "\n",
    "#  you can add any additional parameters you want\n",
    "#  TODO:\n",
    "#  Forward propagation implementation should be here\n",
    "    def forward(self, X):\n",
    "        out = self.layer1(X)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(-1, self.num_flat_features(out))\n",
    "        out = (self.fc(out))\n",
    "        return out\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ioU02PmPMmlA"
   },
   "source": [
    "#### Training and Testing [17 pts]\n",
    "\n",
    "Now, train your network. You need to select the appropriate loss function and your hyper-parameters.<br>\n",
    "Make sure to shuffle the samples in the training split.<br>\n",
    " Plot the training and validation loss for each iteration. Also plot the training  and validation accuracy as another figure.<br>\n",
    "  Your model is going to run upto the \"max_epoch\" parameter. Pick the best model as your final model and save this model as a \".pth\" file. Note that the best accuracy does not always imply the best model. Try to track losses instead of accuracies. <br>\n",
    "  Report the test performance change (In terms of accuracy, F1 score, precision and recall) between MLP and CNN and explain the reason for this change explicitly, if there is any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swWSqCgnMmlD"
   },
   "outputs": [],
   "source": [
    "max_epoch = 200\n",
    "train_batch = 10\n",
    "val_batch = 20\n",
    "test_batch = 20\n",
    "learning_rate = 0.005\n",
    "\n",
    "\n",
    "# Inspired from: https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = get_dataset(\"./\", \"./\")\n",
    "\n",
    "def main(train_results, val_results):  # you are free to change parameters\n",
    "\n",
    "    # Create train dataset loader\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch, num_workers=0, shuffle=True)\n",
    "\n",
    "    # Create validation dataset loader\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=test_batch, num_workers=0)\n",
    "\n",
    "    # initialize your GENet neural network\n",
    "    model = ConvNet()\n",
    "\n",
    "    # define your loss function\n",
    "    pos_weight = torch.FloatTensor([2])\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.SGD(list(model.parameters()), lr=learning_rate, momentum=0.9,\n",
    "                                weight_decay=5e-04)  # you can play with momentum and weight_decay parameters as well\n",
    "\n",
    "\n",
    "    # start training\n",
    "    # for each epoch calculate validation performance\n",
    "    # save best model according to validation performance\n",
    "\n",
    "    best_acc = 0\n",
    "    best_loss = 100\n",
    "    best_path = \"Convnet_best_model.pth\"\n",
    "    for epoch in range(max_epoch):\n",
    "        res = train(epoch, model, criterion, optimizer, train_loader)\n",
    "        train_results.append(res)\n",
    "        res = test(model, val_loader, criterion)\n",
    "        acc = res[0]\n",
    "        loss = res[1]\n",
    "        val_results.append(res)\n",
    "        if loss < best_loss:\n",
    "            best_acc = acc\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "\n",
    "''' Train your network for a one epoch '''\n",
    "\n",
    "\n",
    "def train(epoch, model, criterion, optimizer, loader):  # you are free to change parameters\n",
    "    model.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "\n",
    "\n",
    "    t1 = time.time()\n",
    "    for batch_idx, (data, labels) in enumerate(loader):\n",
    "        data_time.update(time.time() - t1)\n",
    "\n",
    "        #data, labels= Variable(data), Variable(labels)\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Implement training code for a one iteration\n",
    "        x = data\n",
    "        labels = labels.float()\n",
    "        output = model(x)\n",
    "        loss = criterion(output.reshape(1,train_batch)[0].float(), labels)\n",
    "        predicted = (output>0.0).float()\n",
    "        acc = sum([1 if item[0] == item[1] else 0 for item in zip(predicted, labels)]) / len(labels)\n",
    "        accuracies.update(acc, x.size(0))\n",
    "        losses.update(loss.item(), x.size(0))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - t1)\n",
    "        t1 = time.time()\n",
    "\n",
    "        print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "              'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "              'Data {data_time.val:.4f} ({data_time.avg:.4f})\\t'\n",
    "              'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "              'Accu {acc.val:.4f} ({acc.avg:.4f})\\t'.format(\n",
    "            epoch + 1, batch_idx + 1, len(loader),\n",
    "            batch_time=batch_time,\n",
    "            data_time=data_time,\n",
    "            loss=losses,\n",
    "            acc=accuracies))\n",
    "\n",
    "    return accuracies.avg, losses.avg\n",
    "\n",
    "\n",
    "''' Test&Validate your network '''\n",
    "\n",
    "\n",
    "def test(model, loader, criterion):  # you are free to change parameters\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t1 = time.time()\n",
    "        for batch_idx, (data, labels) in enumerate(loader):\n",
    "            # Implement test code\n",
    "            x = data\n",
    "            output = model(x)\n",
    "            labels = labels.float()\n",
    "            loss = criterion(output.reshape(1,test_batch)[0].float(), labels)\n",
    "            predicted = (output>0.0).float()\n",
    "            acc = sum([1 if item[0] == item[1] else 0 for item in zip(predicted, labels)]) / len(labels)\n",
    "            accuracies.update(acc, x.size(0))\n",
    "            losses.update(loss.item(), x.size(0))\n",
    "            batch_time.update(time.time() - t1)\n",
    "            t1 = time.time()\n",
    "\n",
    "        print('Time {batch_time.avg:.3f}\\t'\n",
    "              'Accu {acc.avg:.4f}\\t'\n",
    "              'Loss {loss.avg:.4f}\\t'.format(\n",
    "            batch_time=batch_time,\n",
    "            acc=accuracies,\n",
    "            loss=losses))\n",
    "\n",
    "        return accuracies.avg, losses.avg\n",
    "\n",
    "\n",
    "train_res = list()\n",
    "val_res = list()\n",
    "main(train_res, val_res)\n",
    "\n",
    "train_acc, train_loss = zip(*train_res)\n",
    "val_acc, val_loss = zip(*val_res)\n",
    "\n",
    "plt.plot(range(1, max_epoch+1), train_acc, label=\"train_acc\")\n",
    "plt.plot(range(1, max_epoch+1), val_acc, label=\"val_acc\")\n",
    "plt.title(\"Epoch - Accuracy Graph\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, max_epoch+1), train_loss, label=\"train_loss\")\n",
    "plt.plot(range(1, max_epoch+1), val_loss, label=\"val_loss\")\n",
    "plt.title(\"Epoch - Loss Graph\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# write your code in this cell to test your best model with the test dataset\n",
    "# Create test dataset loader\n",
    "testloader = DataLoader(test_dataset, batch_size=test_batch)\n",
    "\n",
    "best_path = \"Convnet_best_model.pth\"\n",
    "model = ConvNet()\n",
    "checkpoint = torch.load(best_path)\n",
    "if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "batch_time = AverageMeter()\n",
    "accuracies = AverageMeter()\n",
    "\n",
    "labels_list = list()\n",
    "predictions_list = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    t1 = time.time()\n",
    "    for batch_idx, (data, labels) in enumerate(testloader):\n",
    "        # Implement test code\n",
    "        x = data\n",
    "        output = model(x)\n",
    "        predicted = (output>0.0).float()\n",
    "        labels_list.append(list(np.asarray(labels)))\n",
    "        predictions_list.append(list(np.asarray(predicted)))\n",
    "        acc = sum([1 if item[0] == item[1] else 0 for item in zip(predicted, labels)]) / len(data)\n",
    "        accuracies.update(acc, x.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - t1)\n",
    "        t1 = time.time()\n",
    "\n",
    "    print('Time {batch_time.avg:.3f}\\t'\n",
    "          'Accu {acc.avg:.4f}\\t'.format(\n",
    "        batch_time=batch_time,\n",
    "        acc=accuracies))\n",
    "\n",
    "predictions_list = [item for sublist in predictions_list for item in sublist]\n",
    "labels_list = [item for sublist in labels_list for item in sublist]\n",
    "a = np.array(predictions_list)\n",
    "b = np.array(labels_list)\n",
    "tp = 0\n",
    "for i in range(500):\n",
    "    if a[i] == 1 and b[i] == 1:\n",
    "        tp += 1\n",
    "tn = 0\n",
    "for i in range(500):\n",
    "    if a[i] == 0 and b[i] == 0:\n",
    "        tn += 1\n",
    "fp = 0\n",
    "for i in range(500):\n",
    "    if a[i] == 1 and b[i] == 0:\n",
    "        fp += 1\n",
    "fn = 0\n",
    "for i in range(500):\n",
    "    if a[i] == 0 and b[i] == 1:\n",
    "        fn += 1\n",
    "\n",
    "print(\"\\n   Labels\\n\")\n",
    "print(tp, \"    \", fp)\n",
    "print(\"               predictions\" )\n",
    "print(fn, \"    \", tn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Measure: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[loss2.png](https://drive.google.com/open?id=1x8skTJ81lwnGWHNUgqBgaMtrtRmXs7HV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[acc2.png](https://drive.google.com/open?id=1Mr-7hWL9CB2oWQNxkWHT9rhiWKkr8gDW)\n",
    "<br>\n",
    "I added these images to zip file, as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.5620\t\n",
    "<br>\n",
    "   Labels<br>\n",
    "\n",
    "(90  ,  133)     \n",
    "(86  ,  191) predictions<br>\n",
    "\n",
    "Precision:  0.40358744394618834<br>\n",
    "Recall:  0.5113636363636364<br>\n",
    "F1 Measure:  0.4511278195488722<br>\n",
    "\n",
    "\n",
    "MLP had a much better recall. Also, it had a consistent training & test accuracy rates. However, CNN overfitted to the training data, needs some batch normalization. In additon, though CNN yielded higher accuracy, the reason is that majority of samples are negative and CNN has a tendency to predict class 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCDpcMJTHD0h"
   },
   "source": [
    "### 2.3 Interpretation [10 pts.]\n",
    "\n",
    "Explicitly discuss the results that you have obtained in Question 2. <ul>\n",
    "    1. > Among MLP and CNN , which one do you think is better? <br>\n",
    "    2. > What are the weaknesses and strengths of each method?<br>\n",
    "    3. > Why do we use max pooling layers for CNN? What would happen if we used average pooling instead? <br>\n",
    "    4. > How can we interpret the weights of convolutional layers? <br>\n",
    "    </ul>\n",
    " \n",
    "1. Before implementing I thought MLP is insufficient for this task. It resulted in 50% accuracy and 67% recall for the given task. However, CNN overfitted to training data and did not result in good test accuracy. Also, it is computationally more and more expensive than MLP. Thus, for this particular question I choose MLP.\n",
    " \n",
    "2. The most important weakness of MLP for this task is that it cannot take multiple dimensions of the images into account. That's why we flattened the data before implenting the model. One of the other main limitation of the MLP algorithm is that, because of the way it is trained, it can not guarantee that the minima it stops at during training is the global minima. The MLP algorithm can, therefore, get stuck in a local minima. Also, because of imbalanced class distribution MLP model had a tendency to predict all samples as normal/non-disease. However, MLP is very strong in terms of time. It results in a really short time.\n",
    "\n",
    "    The most significant weakness of CNN is that it is computationally too expensive and takes more and more time than MLP. Also, it might overfit when training set is not big enough. Class imbalance problem is also one of the weakness of CNN. However, when small issues are solved, it is really strong algorithm that predicts test samples with really high accuray.\n",
    " \n",
    "3. We use pooling techniques to reduce variance, reduce computation complexity (as 2 x 2 pooling reduces 75% data) and extract low level features from neighbourhood. Max pooling extracts the most important features like edges whereas, average pooling extracts features so smoothly. Although both are used for same reason, I think max pooling is better for extracting the extreme features. Average pooling sometimes can’t extract good features because it takes all into count and results an average value which may/may not be important for object detection type tasks. Average pooling brings all into count and flows it to next layer which means all values actually are used for feature mapping and creating output - which is a very generalized computation. If we don’t need all inputs from Conv layer, we will get bad accuracy for average pooling. \n",
    "    \n",
    "    If we used average pooling, it would perform worse than max pooling because our input images have black background. Average pooling would decrease the sharpness of transition between pixels. We could use it if our background color was white. \n",
    "\n",
    "4. In their first layers, convolutional neural nets have ‘filters’. The input is a n x n x 3 size grid (depth three for RGB) image (at least in the image classification case). So the convolutional net has a filter that might be, say 5 x 5 x 3. This filter is element-wise multiplied by a 5 x 5 x 3 piece of the input, then the results are summed. This creates one output element.\n",
    "\n",
    "Then, the filter is slid (or convolved), so it is now multiplied by a different section of the input, but the filter still has the same weights. This creates another output element.\n",
    "\n",
    "Hence the shared weights. Each filter is slid along the image, and applied to different parts of the image. The values of the image change from location to location, but the weights of the filter (i.e. the numbers by which the piece of image is multiplied) stay the same. Thus, many of the output elements are produced by the same filter weights, hence the term ‘shared weights’.\n",
    "\n",
    "Weights are the numbers within each filter. So essentially we are trying to learn a filter. These filters act on a certain receptive field/ small section of the image. When the filter moves through the image, the filter does not change. The idea being, if an edge is important to learn in a particular part of an image, it is important in other parts of the image too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7q8jg7nfFUe-"
   },
   "source": [
    "##References\n",
    "\n",
    "Ocular Disease Recognition - ODIR5k Dataset (https://www.kaggle.com/andrewmvd/ocular-disease-recognition-odir5k)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS464_HW3_Spring20.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
